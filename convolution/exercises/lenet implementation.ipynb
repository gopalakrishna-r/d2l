{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid',\n",
    "                               padding='same'),\n",
    "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=5,\n",
    "                               activation='sigmoid'),\n",
    "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(84, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(10)])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform((1, 28, 28, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCallback(tf.keras.callbacks.Callback):  #@save\n",
    "    \"\"\"A callback to visiualize the training progress.\"\"\"\n",
    "    def __init__(self, net, train_iter, test_iter, num_epochs, device_name):\n",
    "        self.timer = d2l.Timer()\n",
    "        self.animator = d2l.Animator(\n",
    "            xlabel='epoch', xlim=[1, num_epochs], legend=[\n",
    "                'train loss', 'train acc', 'test acc'])\n",
    "        self.net = net\n",
    "        self.train_iter = train_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device_name = device_name\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.timer.start()\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.timer.stop()\n",
    "        test_acc = self.net.evaluate(\n",
    "            self.test_iter, verbose=0, return_dict=True)['accuracy']\n",
    "        metrics = (logs['loss'], logs['accuracy'], test_acc)\n",
    "        self.animator.add(epoch + 1, metrics)\n",
    "        if epoch == self.num_epochs - 1:\n",
    "            batch_size = next(iter(self.train_iter))[0].shape[0]\n",
    "            num_examples = batch_size * tf.data.experimental.cardinality(\n",
    "                self.train_iter).numpy()\n",
    "            print(f'loss {metrics[0]:.3f}, train acc {metrics[1]:.3f}, '\n",
    "                  f'test acc {metrics[2]:.3f}')\n",
    "            print(f'{num_examples / self.timer.avg():.1f} examples/sec on '\n",
    "                  f'{str(self.device_name)}')\n",
    "\n",
    "#@save\n",
    "def train_ch6(net_fn, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    device_name = device._device_name\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device_name)\n",
    "    with strategy.scope():\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        net = net_fn()\n",
    "        net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    callback = TrainCallback(net, train_iter, test_iter, num_epochs,\n",
    "                             device_name)\n",
    "    net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the average pooling with maximum pooling. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters = 6, kernel_size = 5, activation=tf.nn.sigmoid, padding='same'), \n",
    "        tf.keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation=tf.nn.sigmoid),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(120, activation=tf.nn.sigmoid),\n",
    "        tf.keras.layers.Dense(84, activation=tf.nn.sigmoid),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to construct a more complex network based on LeNet to improve its accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the convolution window size.\n",
    "\n",
    "Adjust the activation function (e.g., ReLU).\n",
    "\n",
    "Adjust the learning rates and other training details (e.g., initialization and number of epochs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from  keras_tuner import HyperParameters as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(hp: kt.HyperParameters):\n",
    "    activation = hp.Choice( name = 'activation', values = ['sigmoid', 'elu', 'relu'], ordered = False)\n",
    "    filters = hp.Choice(name = 'filters', values = [4, 8, 16, 32])\n",
    "    kernel_size = hp.Choice(name = 'kernel_size', values =[3, 5, 7])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    optimzer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    net = tf.keras.Sequential()\n",
    "    for _ in range(hp.Int('conv_layers', 1, 3, default=3)):\n",
    "            net.add(tf.keras.layers.Conv2D(filters , kernel_size, activation= activation))\n",
    "    net.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))           \n",
    "    net.add(tf.keras.layers.Flatten())\n",
    "    net.add(tf.keras.layers.Dense(hp_units, activation=tf.nn.sigmoid))\n",
    "    net.add(tf.keras.layers.Dense(hp_units, activation=tf.nn.sigmoid))\n",
    "    net.add(tf.keras.layers.Dense(10))\n",
    "    net.compile(optimizer = optimzer, loss = loss, metrics = ['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    net,\n",
    "    objective=kt.Objective('accuracy', direction='max'),max_epochs=50, factor=2,directory=\"results_dir\",\n",
    "    project_name=\"mnist\", distribution_strategy=tf.distribute.OneDeviceStrategy(d2l.try_gpu()._device_name), overwrite=True, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_iter, epochs = 50, workers = 8, use_multiprocessing=True, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model =  tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model.evaluate(test_iter)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78b3ca1ae7c0abb97248981ef3fd734c0a5df63e41592f9ee693c79d9cedd4a6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
