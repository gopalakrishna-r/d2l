{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[Reading the DataSet](#reading_the_dataset)<br>\n",
    "[Handling Missing Data](#handling_missing_data)<br>\n",
    "[Conversion to the Tensor Format](#tensor_format_conversion)<br>\n",
    "[Exercises](#exercises)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### reading the dataset\n",
    "<a id = 'reading_the_dataset'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "def mkdir_if_not_exist(path):\r\n",
    "    \"\"\"make a directory if it does nto exit.\"\"\"\r\n",
    "    if not isinstance(path, str):\r\n",
    "        path = os.path.join(*path)\r\n",
    "    if not os.path.exists(path):\r\n",
    "        os.makedirs(path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_file = '../data/house_tiny.csv'\r\n",
    "mkdir_if_not_exist('../data')\r\n",
    "with open(data_file, 'w') as f:\r\n",
    "    f.write('NumRooms,Alley, Price \\n')\r\n",
    "    f.write('NA,Pave,127500\\n')\r\n",
    "    f.write('2,NA,106000\\n')\r\n",
    "    f.write('4,NA,178100\\n')\r\n",
    "    f.write('NA,NA,140000')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "data = pd.read_csv(data_file)\r\n",
    "print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handling Missing Data\n",
    "<a id= 'handling_missing_data'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\r\n",
    "inputs = inputs.fillna(inputs.mean())\r\n",
    "print(inputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#for columns with categorical values like alley, Nan is treated a true/false in conjuction with absolute value\r\n",
    "inputs = pd.get_dummies(inputs, dummy_na = True)\r\n",
    "print(inputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversion to the Tensor format\n",
    "<a id='tensor_format_conversion'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X, y = tf.constant(inputs.values), tf.constant(outputs.values)\r\n",
    "X, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3), dtype=float64, numpy=\n",
       " array([[3., 1., 0.],\n",
       "        [2., 0., 1.],\n",
       "        [4., 0., 1.],\n",
       "        [3., 0., 1.]])>,\n",
       " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([127500, 106000, 178100, 140000], dtype=int64)>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises\n",
    "<a id='exercises'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a raw dataset with more rows and columns.\n",
    "\n",
    "Delete the column with the most missing values.\n",
    "\n",
    "Convert the preprocessed dataset to the tensor format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data_file = '../data/oscars_tiny.csv'\n",
    "mkdir_if_not_exist('../data')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('movie_name,year_released, Price \\n')\n",
    "    f.write('NA,Pave,127500\\n')\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "360eb45faca1e4dfefc4f13aa9499776008d91528b4d443d812d58097d713eb4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}